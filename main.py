import os
import streamlit as st
from dotenv import load_dotenv
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAI
from langchain.chains import RetrievalQA

# Load environment variables
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Validate API key
if not OPENAI_API_KEY:
    st.error("âš ï¸ OpenAI API key is missing! Please add it to your `.env` file.")
    st.stop()

# Streamlit UI
st.title("ğŸ“° News Research Tool ğŸ“ˆ")
st.sidebar.title("ğŸ”— Enter News URLs")

# Input URLs
urls = []
for i in range(3):
    url = st.sidebar.text_input(f"URL {i+1}")
    if url:
        urls.append(url)  # Add only non-empty URLs

# Process button
process_url_clicked = st.sidebar.button("ğŸš€ Process URLs")

# File paths for FAISS storage
FAISS_INDEX_PATH = "faiss_index"

# Load OpenAI model
llm = OpenAI(temperature=0.3, model_name="gpt-4", openai_api_key=OPENAI_API_KEY)

if process_url_clicked:
    if not urls:
        st.warning("âš ï¸ Please enter at least one URL before processing.")
    else:
        st.write("ğŸ”„ Fetching and processing articles...")

        # âœ… Load articles using Playwright
        loader = WebBaseLoader(urls)
        docs = loader.load()

        if not docs:
            st.error("âš ï¸ No valid data retrieved from the URLs. Please check and try again.")
            st.stop()

        # âœ… Split text into chunks
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        doc_chunks = text_splitter.split_documents(docs)

        # âœ… Generate embeddings and store in FAISS
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectorstore = FAISS.from_documents(doc_chunks, embeddings)

        # âœ… Save FAISS index
        vectorstore.save_local(FAISS_INDEX_PATH)
        st.success("âœ… Data indexed successfully!")

# Query Input
query = st.text_input("ğŸ” Ask a question based on the articles:")

if query:
    # âœ… Load FAISS index if available
    if os.path.exists(FAISS_INDEX_PATH):
        embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
        vectorstore = FAISS.load_local(FAISS_INDEX_PATH, embeddings)

        # âœ… Setup RetrievalQA
        retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
        chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

        # âœ… Get answer
        st.write("ğŸ¤– Generating answer...")
        result = chain.invoke({"query": query})

        # âœ… Display answer
        st.header("ğŸ“¢ Answer:")
        st.write(result["result"])
    else:
        st.error("âš ï¸ No FAISS index found. Please process URLs first!")
